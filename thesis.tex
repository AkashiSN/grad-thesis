% ------------------------------------------------------
% preamble
% ------------------------------------------------------

\documentclass[autodetect-engine, dvipdfmx-if-dvi, a4paper, ja=standard, 10pt, textwidth-limit=45]{bxjsreport}

\input{preamble/thesis}

\subtitle{令和元年度卒業研究論文}
\title{URLの情報指向型クラシフィケーション}
\date{2020年2月7日(金)}
\supervisor{指導教員 井上一成 教授}
\institute{明石工業高等専門学校電気情報工学科}
\author{報告者 E1533 西 総一朗}

\begin{document}

% ------------------------------------------------------
% front cover
% ------------------------------------------------------

\maketitle
\thispagestyle{empty}

\clearpage

% ------------------------------------------------------
% table of contents
% ------------------------------------------------------

\pagenumbering{roman}
\setcounter{tocdepth}{2}
\tableofcontents

\clearpage

% ------------------------------------------------------
% body
% ------------------------------------------------------

\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{序論}
\section{TCP/IPの課題}
1983年から今日のインターネットと呼ばれているネットワークにおいて通信プロトコルTCP/IPがデファクトスタンダードとなった\cite{Brief_History_of_the_Internet}．
約20年前のインターネットのトラヒックや利用形態は現在とは大きく異なっている．
1992年の全世界のインターネットトラフィックは1日あたり約100 GBであったが,その10年後の2002年には1秒あたり100 GBに増え，2017年には1秒あたり45,000 GB以上に到達した．
また利用形態も2017年においてはトラヒックの75\%をビデオコンテンツが占めている．
Ciscoによると全世界のインターネットトラヒックは2022年には150,700 GB/秒となりその82\%をビデオコンテンツが占めると予測されている\cite{Cisco_Visual_Networking_Index}．

また，インターネットの使用目的も変遷している．
当初はインターネットを高性能コンピュタあるいは高性能プリンタを利用するように，様々なリソースを遠隔から共有することが主な目的であった．
現在は情報の共有，情報の取得といった情報のやり取りが中心となっている．
それに伴って，通信形態も変化している．
従来のTCP/IPはホスト中心のHost-to-Hostの通信形態であり，IPプロトコルは位置情報であるネットワークアドレスを用いてホストアドレスを指定するというロケーション・オリエンテッド\footnote{Location-oriented: 地理的指向な}な通信であった．
ところが，現在は情報をユーザに送るというインフォメーション・セントリック\footnote{Information-Centric: 情報指向な}な通信形態に変わりつつある．

このようにTCP/IPの通信形態と現在のインターネットに求められている通信形態との間の差が広がっている．
そこで，情報の効率的な取得のために
P2P\footnote{Peer to Peer: インターネットにおいて一般的に用いられるクライアント・サーバ型モデルでは，データを保持・提供するサーバとそれに対してデータを要求・アクセスするクライアントという2つの立場が固定されているのに対して，各ピアに対して対等 にデータの提供及び要求・アクセスを行う自立分散型のネットワークモデル．}や
CDN\footnote{Content Delivery Network: 頻繁に使われるWebサイトがあると一つのノード（サーバ）のみでは負荷が集中するためいくつかのノードにデータを分散しておき，各ユーザは分散したノードに接続して情報を取得するという方法．}などの新しいプロトコルが提案された．
しかし，これらはロケーション・セントリックなTCP/IPネットワーク上のプロトコルであるので本質的な解決ではない．
本来，情報を取得するという行為に対して，ネットワークアドレスやホストアドレスなどを意識する必要はなく，
もし近くにある通信機器が当該コンテンツ(情報)\footnote{参考文献\cite{Networking_Named_Content}では情報(Information)とコンテンツ(Contents)は同様の意味で用いられている．本稿でも同様の意味で用いる．}を持っておりそこから情報を取得できるなら，それはより効率的であり将来の通信量増大にも対応できると考えられる．
そこで，情報を効率的に取得するために情報指向ネットワーク:\ Information-Centric-Network (ICN)\cite{Networking_Named_Content}というプロトコル体系が提案された\cite{ICN_prototype}．

\section{情報指向ネットワーク}
情報指向ネットワーク(ICN)においてユーザはサーバのIPアドレスではなくコンテンツ名を指定してコンテンツ取得要求を行う．
そのコンテンツ要求を受け取った近隣のルータやノードが当該コンテンツを保持していた場合，それらはユーザに対してそのコンテンツを直接転送する．
ICNでは情報を保持している者をパブリッシャ(Publisher)，情報の取得要求を出すものをサブスクライバ(Subscriber)と呼び，
各コンテンツ(情報)に対してコンテンツ名(名前)が対応付けられている．

ICNへのアプローチとして様々な研究がなされているが，現在最も多くの研究者により研究されているNamed Data Networking (NDN)\cite{NDN} 及びその前身であるContent Centric Networking (CCN)\cite{CCN} を代表的なICNアーキテクチャとして述べる．
CCNアーキテクチャはパロアルト研究所\footnote{Palo Alto Research Center (PARC) : アメリカ合衆国のカリフォルニア州パロアルトにある研究開発企業}により研究されているICNの先駆となった本格的なアーキテクチャである．
また，US Future Internet Architectureプログラム\footnote{NSF FUTURE INTERNET ARCHITECTURE PROJECT (http://www.nets-fia.net/)}によって資金提供されたNDNプロジェクトは，CCNアーキテクチャをさらに発展させたものである．

\paragraph{コンテンツ名}
NDNにおけるコンテンツ名の命名規則は階層構造になっており，現在のインターネットで流通している識別子であるUniform-Resource-Locator (URL)に似ている．
たとえば，コンテンツ名は\url{/aueb.gr/ai/main.html}となる．
ただし，コンテンツ名は必ずしもURLとは一致せず，最初のセクション\footnote{"/"で区切られた部分をセクションと呼ぶ．}はDNS名またはIPアドレスなどの形式である必要もない．
つまりNDNでは，各セクションについての具体的な規格は定義されていない．
またコンテンツ取得要求において，要求されたコンテンツ名のプレフィックスの名前を持つ情報と一致すると見なされる．
たとえば，\url{/aueb.gr/ai/main.html/_v1/_s1}は\url{/aueb.gr/ai/main.html}という名前のコンテンツと一致する．
これは要求されたコンテンツの初版であり，コンテンツを分割したセグメントの最初のデータを表している．
このデータを受信したあとにSubscriberは\url{/aueb.gr/ai/main.html/_v1/_s2}により次のセグメントを要求することや，新たなバージョンを要求することもできる．
このようにコンテンツを分割して扱う際にはコンテンツ名にそのメタデータを付与することが可能である．

\paragraph{名前解決とデータルーティング}
NDNにおいて，Subscriberはコンテンツを取得する際はコンテンツ取得要求であるINTERESTパケットを発行して，PublisherからのDATAパケットの形式で到着するコンテンツを取得する．
INTEREST/DATAパケットは，それぞれ要求/転送されるコンテンツのコンテンツ名を持つ．
Fig. \ref{fig:ccn_ndn_routing}に示すように，すべてのパケットはContent Router (CR)によってホップバイホップ(hop by hop)で転送される．
各CRには3つのデータ構造(Forwarding Information Base (FIB), Pending Interest Table (PIT), Content Store (CS))がある．
FIBは，INTERESTパケットを適切なデータソースに転送するために使用するインターフェイスとコンテンツ名をマッピングする．
PITは，保留中のINTERESTパケットが到着した受信インターフェイス，つまり一致するDATAパケットが転送されてきたときに返送するインターフェースとコンテンツ名をマッピングすることでINTERESTパケットを追跡する．
最後に，CSはCRを通過したコンテンツのローカルキャッシュとして機能する.

INTERESTパケットが到着すると，CRはコンテンツ名を抽出し要求されたプレフィックスと一致する名前を持つCSのコンテンツを探す．
CSでキャッシュが見つかった場合，すぐにDATAパケットとして受信インターフェイスを介して返送され，INTERESTパケットは破棄される．
それ以外の場合，CRはこのINTERESTパケットを転送するインターフェースを決定するために，FIBで最長プレフィックス検索を実行する．
FIBでエントリが見つかった場合，CRはPITにINTERESTパケットの受信インターフェイスとコンテンツ名を記録し，FIBが示すCRにINTERESTパケットを転送する．
Fig. \ref{fig:ccn_ndn_routing}では，Subscriberは\url{/aueb.gr/ai/new.htm}という名前のINTERESTパケットを送信する(矢印1〜3)．
PITにコンテンツ名のエントリが既に含まれている場合，つまりこのコンテンツが既に要求されている場合，CRは受信インターフェイスをこのPITエントリに追加し，INTERESTパケットを破棄する．

要求されたコンテンツ名に一致するコンテンツがPublisherまたはCSで見つかった場合，INTERESTパケットは破棄され，コンテンツはDATAパケットとして返送される．
このDATAパケットは，PITで維持されている状態に基づいてホップバイホップ方式でSubscriberに転送される．
具体的には，CRはDATAパケットを受信すると，対応するコンテンツをCSに保存し，PITで最長プレフィックス検索を実行して，DATAパケットに一致するエントリを見つける．
PITエントリに複数のインターフェイスがある場合，DATAパケットが複製され，マルチキャスト配信が実現される．
最後に，CRはDATAパケットをこれらのインターフェイスに転送し，PITからエントリを削除する(矢印4〜6)．
PITに一致するエントリがない場合，CRはDATAパケットを重複データとして破棄する．
NDNでは，DATAパケットはINTERESTパケットによってPITに残された経路に従うため，名前解決とデータルーティングは対称である\cite{A_Survey_of_Information-Centric_Networking_Research}．

\section{ICNの実用化に向けた課題}
ICNにおけるContents Router (CR)は未だに研究段階にありソフトウェアとして参照実装\footnote{Cefore: \url{https://cefore.net/} NICTにより開発されたCCNx準拠のTCP/IP上でCCNパケットをシミュレートするソフトウェアルータ}はあるが，ハードウェアとして実装されたものはない．
ICNの実用化を行うため，CRのハードウェアによる実装が不可欠である．
ハードウェア実装に向けた課題として，TCP/IPにおけるIPアドレスの代わりにコンテンツ名を用いて名前解決とルーティングを行うためCRでの処理が複雑であり，各テーブルに必要な記憶容量も増加するという点が挙げられる．
この問題を解決するためにコンテンツ名に対してハッシュ化\footnote{本稿ではあるデータを規則に則って処理したときに出力されるものをハッシュ，その規則をハッシュアルゴリズム，またこの処理を行うことをハッシュ化と呼ぶ．}を行うことによりルーティングに用いる識別子の圧縮などが研究されている\cite{saino2013hash}\cite{bloom_filter}．
しかし，これらは既存のハッシュアルゴリズムを用いているため，ハードウェアで実装するには複雑である．
また，ICNにおけるコンテンツ名のハッシュ化という用途では完全に衝突のないハッシュを用いるより，多少の衝突を許容しながらも高速に計算可能なハッシュアルゴリズムが求められる．
この多少の衝突を許容するために各テーブルにおける新たなデータ構造による検索手法も求められる．

\section{本研究の目的}
本研究では，上記課題を解決するために新たなデータ構造による検索手法と高速で軽量なハッシュアルゴリズムを提案，検証することである．
コンテンツ名はランダムな文字列ではなくある程度自然言語的な規則があるのでそれを用いることで軽量化を図る．

\section{本論文の構成}
本論文は本章を含め4章で構成されている．
第2章では，URLの階層構造とICNのコンテンツ名の関係を述べたのちハッシュアルゴリズムの解析方法について説明する．
第3章では，性能評価の結果を記述する．
最後に，第4章において，本論文を通して得られた結果をまとめる．

\begin{figure}
  \centering
  \includegraphics[scale=0.9]{fig/CCN_NDN_Routing-crop.pdf}
  \caption{The CCN/NDN architecture．CR stands for Content Router, FIB for Forwarding Information Base, PIT for Pending Interest Table, CS for Content Store (Excerpt from \cite{A_Survey_of_Information-Centric_Networking_Research})．}
  \label{fig:ccn_ndn_routing}
\end{figure}


\chapter{解析手法}

\section{URLの構造}
NDNのコンテンツ名はURLに似ているのでURLの階層構造について調べる．
Uniform-Resource-Locator(URL)はRFC1738\cite{rfc1738}により規格化されており，リソースの位置を特定するために用いられる．
HTTP URLの構造は
\begin{center}
  \begin{BVerbatim}
<scheme>://<host>:<port>/<path>?<searchpart>
  \end{BVerbatim}
\end{center}

\noindent
である．また，Table \ref{tab:http_url_variables_description}に各変数の説明を示す．
\begin{table}[h]
  \centering
  \label{tab:http_url_variables_description}
  \caption{HTTP URL variables description\cite{rfc1738}．}
  \begin{tabular}{@{}cp{12cm}@{}}
    \toprule
    Variables & \multicolumn{1}{c}{Description} \\ \midrule
    \verb|<scheme>| & \verb|http|, \verb|https|などのプロトコルを表す． \\
    \verb|<host>| & ネットワークホストのドメイン名，またはIPアドレス．ドメイン名は"."によって区切られるドメインラベルの連続． \\
    \verb|<port>| & 接続先のポート番号．デフォルトのポート番号(80, 443)以外のポートを指定するときのみコロンで区切って続ける．\\
    \verb|<path>| & HTTPセレクタでリソースの位置を指定する． \\
    \verb|<searchpart>| & 検索パラメータ．これが省略されたときは"?"も省略される． \\ \bottomrule
  \end{tabular}
\end{table}

URLは\url{host}部によって階層構造に分けることができる．
\url{host}部はドメイン名またはIPアドレスによって構成されているが，ここでは一般に多く使われているドメイン名のみに注目する．
Domain Name System (DNS)は木構造でありドメイン名にはその階層構造が反映されている．
前述のドメイン名とは実際にはFully Qualified Domain Name (FQDN)\cite{rfc1983}のことであり，Fig. \ref{fig:fqdn_structure}のような構造である．
FQDNは"."で区切られた各ラベルの連続であり右端の"."がルートとなる．
ルートから順に各ラベルはTop-Level Domain (TLD), Second-Level Domain (SLD), 3rd-Level Domain (3rdLD), 4th-Level Domain (4thLD), ... のように名前がつけられている．
また左端のラベルをHost Nameと呼び，それ以外のラベルをまとめてDomain Nameと呼ぶ．

Top-Level Domain (TLD)にはcountry code TLD (ccTLD), generic TLD (gTLD), restricted generic TLD (grTLD), sponsored TLD (sTLD)などがありそれぞれICANNにより管理されている\cite{tld}．
それぞれの例をTable \ref{tab:examples_tld}に示す．
\begin{figure}[t]
  \centering
  \includegraphics[scale=1.4]{fig/fqdn_structure-crop.pdf}
  \caption{Fully Qualified Domain Name (FQDN) structure. FQDN ends with a period. TLD stands for Top-Level Domain, SLD for Second-Level Domain, 3rdLD for 3rd-Level Domain, 4thLD for 4t-Level Domain．}
  \label{fig:fqdn_structure}
\end{figure}
\begin{table}[t]
  \centering
  \caption{Examples of each TLDs．}
  \label{tab:examples_tld}
  \begin{tabular}{@{}ccccc@{}}
  \toprule
  ccTLD & gTLD & grTLD & sTLD & eTLD\\ \midrule
  \url{.jp} & \url{.com} & \url{.biz} & \url{.aero} & \url{.co.jp} \\ 
  \url{.uk} & \url{.info} & \url{.name} & \url{.asia} & \url{.ac.jp} \\
  \url{.cn} & \url{.net} & \url{.pro} & \url{.cat} & \url{.akashi.hyogo.jp} \\ \bottomrule
  \end{tabular}
\end{table}

\paragraph{Public Suffix (eTLD)}
各ブラウザによるクッキーの適応可能範囲決定のために“１つのサイト”の単位というものが求められた．それを受けてPublic Suffixというものが提案された\footnote{例えば，\url{example.co.jp}や\url{a.example.co.jp}のPublic Suffixは\url{co.jp}で，\url{example.co.jp}が
サイトの単位となる．もし，\url{example.co.jp}がドメインが\url{co.jp}や\url{jp}のクッキーを発行できてしまうと，異なるサイトであるはずの\url{test.co.jp}にも干渉できてしまう．これを防ぐためにクッキーの処理ではPSLを参照するようになっている．}．
これはeffective TLD (eTLD)とも呼ばれ，TLDや\url{co.jp}などの実質的にTLDのように機能するドメインを指す．
TLD内のサブドメインの構造はTLDごとに異なるため，機械的にeTLDを決定することはできない．
そのためPublic Suffix List (PSL)\cite{psl}として一覧表が管理されている．

\section{ICNにおけるコンテンツ名}
ICNにおけるコンテンツ名を本研究では
\begin{center}
  \begin{BVerbatim}
icn:/<reTLD>/<Root>/<rHostName>/<Path>
  \end{BVerbatim}
\end{center}
のように定義し，ICN-URLと呼ぶ．
\verb|reTLD| (reverse-eTLD)と\verb|rHostName| (reverse-HostName)はそれぞれ\verb|eTLD|と\verb|HostName|を"."を区切りとして逆順に配置したものである．
すなわち，\verb|eTLD|が\verb|ab.cd.ef|なら\verb|reTLD|は\verb|ef.cd.ab|となる．
Fig. \ref{fig:icn_url_structure}に具体例を示す．

\clearpage

\begin{figure}[h]
  \centering
  \includegraphics[scale=1.2]{fig/icn_url_structure-crop.pdf}
  \caption{Example of ICN-URL．}
  \label{fig:icn_url_structure}
\end{figure}


\section{性能の評価手順}
Fig. \ref{fig:ccn_ndn_routing}のテーブルをFig. \ref{fig:ndn_table}に再掲する．
FIB, PIT, CSの３つのテーブルはNameをキーとしており，その分布を評価することでアルゴリズムの性能を評価する．
評価のためにFig. \ref{fig:table}に示す手順を行った．
入手可能な全URLのリスト(All list)から10MB程度のサイズになるようにランダムに抽出したリスト(Sampled list)を作る．
そのリストでURLの規格に合わないものを除外したのち，ICN-URLに変換しeTLDの頻度の多い順に並べる．
順にICN-URLからハッシュを計算してハッシュテーブルを作成し，ハッシュテーブルの各eTLDの先頭アドレスを保持したポインタテーブルを作成する．
作成したハッシュテーブルの中で同一のハッシュ値となっているものを衝突という．
衝突がないほうが性能が良いと考えられるため，衝突数の分布を調べることにより性能を評価する．

\begin{figure}[p]
  \centering
  \includegraphics[scale=1.4]{fig/ndn_table-crop.pdf}
  \caption{Tables of FIB, PIT, CS．}
  \label{fig:ndn_table}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[scale=0.8]{fig/table-crop.pdf}
  \caption{Analysis procedure．}
  \label{fig:table}
\end{figure}


\subsection{解析データ}
解析に用いるデータとして，The Content Name Collection\footnote{\url{http://www.icn-names.net/} にて"The Content Name Collection"というバーゼル大学による情報指向ネットワークのためのデータセットが2019年10月まで公開されていたが，ドメインの有効期限切れのため現在は全く関係のない中国の会社によりドメインが取得されている．}
で公開されている情報指向ネットワークのための膨大なURLのデータセットを用いる．
そのデータセットの内の一つである\url{urls.txt}を使う．
\url{urls.txt}はFig. \ref{fig:urls_txt_10}のように改行で区別されているURLのリストとなっている．
\url{urls.txt}の概要をTable \ref{tab:dataset_overview}に示す．

\begin{figure}[p]
  \centering
  \begin{BVerbatim}
http://www.google.com
http://images.google.com/imgres
http://www.19lou.com
http://www.sfd.com
http://www.baidu.com
http://www.sina.com.cn
http://www.netvibes.com/
http://www.google.com/search
http://images.google.com/
http://wrestlingabrasil.blogspot.com/
...
...
...
  \end{BVerbatim}
  \caption{Samples 10 in the urls.txt．}
  \label{fig:urls_txt_10}
\end{figure}
\begin{table}[h]
  \centering
  \caption{Dataset "urls.txt" overview．}
  \label{tab:dataset_overview}
  \begin{tabular}{@{}cccc@{}}
    \toprule
    Dataset        & Number of URLs                      & unique                 & File size                                            \\ \midrule
    \url{urls.txt} & \multicolumn{1}{r}{$2,144,314,011$} & \multicolumn{1}{r}{no} & \multicolumn{1}{r}{121 GB ($130,782,049,461$ Bytes)} \\ \bottomrule
  \end{tabular}
\end{table}

\url{urls.txt}の前処理として以下の工程を行う．
このデータには重複が含まれているので重複を削除する．
これは60GBほどのサイズで約8.8億件のURLを含み，全URLリストと呼ぶ．
各CRでの実際的なURLは10MBほどであるという仮定の下，ランダムな10MBを抽出し，解析データとした．
ここには約14万件のURLが含まれる．
この解析データ中の各URLをICN-URLに変換する．

\subsection{ハッシュアルゴリズム}
ICN-URLからハッシュ値を求めるアルゴリズムを述べる．
まず，Fig. \ref{fig:hash_separate}に示すようにICN-URLを"/"で分割する．それぞれをセクション(section)と呼ぶ．
また，自然言語には連続した特徴が存在し，3-gramを用いることで曖昧性を解消できるという先行研究\cite{IoTLAN}に基づき3文字の抽出を行う．
その際セクションの文字数が3文字未満の場合はセクションの文字数に応じて次のように３文字にする(パディング)．

\begin{description}
  \item[セクションが1文字のとき] ICN-URLの長さとスラッシュの数を掛けたものをuint16型で2バイト付加する
  \item[セクションが2文字のとき] ICN-URLのスラッシュの数をbyte型として1バイト付加する
\end{description} 

次に，各セクションから前3文字を抜き出して配列headsとする．
同様に後3文字を抜き出して配列tailsとするが，パティングが含まれているセクションはパディングと元の文字との順序を入れ替える．
結果的にheadsとtailsのどちらかに含まれるセクションの数が3未満であればそのURLは処理の対象外とする．

\begin{figure}[h]
  \centering
  \includegraphics[scale=1.35]{fig/hash_separate-crop.pdf}
  \caption{Preparation to make hash．}
  \label{fig:hash_separate}
\end{figure}

先程作成した配列headsとtailsを元に3種類のハッシュアルゴリズムを考案した．

\subsubsection{ハッシュアルゴリズムA}
headsの先頭要素3バイト，tailsの末尾要素3バイト，末尾から3つ目の要素3バイトの各3バイト，計9バイトをそれぞれのバイトごとにXORを計算して3バイトにする．
headsの先頭1文字と先程の3バイトを連結したものを4バイトのハッシュ値とする．
具体例をFig. \ref{fig:hash_A}に示す．

\begin{figure}[h]
  \centering
  \includegraphics[width=120mm]{fig/hash_1-crop.pdf}
  \caption{Hash algorithm A．}
  \label{fig:hash_A}
\end{figure}

\subsubsection{ハッシュアルゴリズムB}
headsの先頭要素3バイト，tailsの末尾要素3バイトのそれぞれのバイトごとにXORを計算し，それを連結して2バイトにする．
headsの先頭1文字と先程の2バイトを連結したものを3バイトのハッシュ値とする．
具体例をFig. \ref{fig:hash_B}に示す．

\subsubsection{ハッシュアルゴリズムC}
headsの先頭要素3バイト，tailsの末尾要素3バイト，末尾から2つ目の要素3バイトのそれぞれのバイトごとにXORを計算し，それを連結して3バイトにする．
headsの先頭1文字と先程の3バイトを連結したものを4バイトのハッシュ値とする．
具体例をFig. \ref{fig:hash_C}に示す．


\subsection{ハッシュテーブル}
約10MBのICN-URLに変換された解析データをreTLD（1番目のセクション）の頻度の多い順に並べる．
これは，eTLDの頻度の多い順と同じである．
各行のICN-URLに対して上記の3種類のハッシュアルゴリズムの内のどれかにより順にハッシュ値を求め，ハッシュテーブルを作成する．
このハッシュテーブルには頻度順の同じeTLDに対応するハッシュ値が連続して並んでいる．
すなわち，eTLDごとにグループ分けされたハッシュテーブルが得られる(Fig. \ref{fig:table}の②)．
新たなeTLDのグループの出現する位置のアドレスをポインタと呼び，それとeTLDとの対応関係をポインタテーブルと呼ぶ(Fig. \ref{fig:table}の①)．

\begin{figure}[H]
  \centering
  \includegraphics[width=135mm]{fig/hash_2-crop.pdf}
  \caption{Hash algorithm B．}
  \label{fig:hash_B}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=135mm]{fig/hash_3-crop.pdf}
  \caption{Hash algorithm C．}
  \label{fig:hash_C}
\end{figure}

\section{解析プログラム}
本研究を行うためにGolangで作成したプログラムの概要を述べる．
各処理の具体的なプログラムコードは付録に掲載する．

\subsection{前処理}
\subsubsection{重複削除}
入力されたデータの重複を削除する．今回は121GBのデータなのでlinuxのuniqコマンドでは時間がかかりすぎるため独自に実装した．
文字数による分割統治法を用いて，分割したデータごとに並行処理を行うことで重複削除の高速化を図った．
重複削除することで60GB程度にデータサイズが削減された．
\subsubsection{サンプル抽出}
重複のないデータから10MB分をランダムに抽出する機能を実装した．
60GBのデータをメモリ上に展開することはできないので，行番号と先頭からのバイト数のテーブルを作成した．
これをメモリ上に展開し，乱数により行番号を選択し，対応するファイル位置を求めファイルポインタを移動させてその行を選択しファイルに出力する．
これを出力したファイルサイズが10MBになるまで繰り返す．
\subsection{コンテンツ名への変換}
バッファに入るだけ読み込んでから並列プロセスに渡して以下の処理をする．
1行読んでURLの構文解析を行いURLの規格に沿っていないものを除外する．
Public Suffix Listとドメイン名を照合してeTLDとRootとHostNameを抽出する．
これを定義したICN-URLの形式に合うように組み立てる．
\subsection{ハッシュテーブルとポインタテーブル生成}
バッファに入るだけ読み込んでから並列プロセスに渡して以下の処理をする．
ICN-URLから3種類のいずれかのハッシュアルゴリズムによりハッシュ値を計算する．
ハッシュ値を順に出力する際に，eTLDと出力バイト数の関係をポインタテーブルとして出力する．
\subsection{衝突数の解析}
作成したハッシュテーブルの中で同一のハッシュ値となっているものを数え上げ，その件数を出力する．
また同一のハッシュ値の数がどのような分布となっているかを確認するために相補累積分布を出力する．


\chapter{性能評価}
ハッシュアルゴリズムの違いや，新たに提案したポインタを用いるデータ構造による衝突数の分布を調べることで性能を評価する．
\section{解析データの妥当性}
全URLリストからランダムに10MB分を抽出した解析データが元の全URLリストの分布と同じ特徴を持っているかを確かめる．
それぞれのeTLDの頻度分布をFig. \ref{graph:sampled_data}に示す．
グラフ中のALL URLsは全URLリスト，Sampled URLsは解析データをそれぞれ示している．
グラフから解析データは全URLリストとほぼ同じ分布を示しており，全URLリストの特徴を代表していると考えることができる．
\begin{figure}[h]
  \centering
  \includegraphics[scale=0.63]{graph/sampled_data/sampled_data-crop.pdf}
  \caption{Probability of eTLD appearance．}
  \label{graph:sampled_data}
\end{figure}

\section{eTLDの分布}
解析データのeTLDの分布を調べる．
その分布をFig. \ref{graph:ratio_of_etld_all}に示す．
Fig. \ref{graph:ratio_of_etld_all}からわかるようにごく少数のeTLDに大半のURLが含まれている．
そこでFig. \ref{graph:ratio_of_etld_detail}とTable \ref{tab:ratio_of_etld_detail}に上位10件の詳細の分布を示す．
解析データのURLの件数は147,315であり，eTLDの上位10件に含まれるURLの件数は125,161である．
すなわち上位10件で85\%を占めている．
この内1位のcomで60\%を占めており，極端に偏っていることがわかる．
これに対する対策が必要と予想される．
\begin{table}[h]
  \centering
  \caption{Top 10 of eTLD, URL count and probability in the sampled URLs (147,315)．}
  \label{tab:ratio_of_etld_detail}
  \begin{tabular}{@{}crrr@{}}
  \toprule
  ID & \multicolumn{1}{c}{eTLD} & \multicolumn{1}{c}{URL count} & \multicolumn{1}{c}{Probability{[}\%{]}} \\ \midrule
  0 & com & 89399 & 60.6856 \\
  1 & net & 8285 & 5.6240 \\
  2 & me & 7720 & 5.2405 \\
  3 & org & 5201 & 3.5305 \\
  4 & de & 3301 & 2.2408 \\
  5 & blogspot.com & 2667 & 1.8104 \\
  6 & jp & 2644 & 1.7948 \\
  7 & co.uk & 2576 & 1.7486 \\
  8 & info & 1783 & 1.2103 \\
  9 & com.br & 1585 & 1.0759 \\ \bottomrule
  \end{tabular}
\end{table}

\begin{figure}
  \centering
  \includegraphics[scale=0.6]{graph/ratio_of_etld/ratio_of_etld_all-crop.pdf}
  \caption{Probability of eTLD appearance in the sampled URLs．}
  \label{graph:ratio_of_etld_all}
\end{figure}
\begin{figure}
  \centering
  \includegraphics[scale=0.6]{graph/ratio_of_etld/ratio_of_etld_detail-crop.pdf}
  \caption{Probability of eTLD appearance in the sampled URLs (top 10 eTLD)．}
  \label{graph:ratio_of_etld_detail}
\end{figure}

\section{ハッシュアルゴリズムの比較}
3種類のハッシュアルゴリズムA--Cを比較するために，解析データ用いてハッシュテーブルを作成した．
そのハッシュテーブルの中で同じハッシュ値を持つICN-URLの数を数え上げて衝突数とする．
そして同じ衝突数を持つICN-URLの合計数を求める．
この合計数の累積のICN-URL総数に対する比率を算出する．これを累積分布と呼ぶ．
累積分布と1との差の絶対値を相補累積分布(Complementary Cumulative Distribution Function: CCDF)と呼ぶ．
これをFig. \ref{graph:hash_ccdf_A-C}に示す．
このグラフではある横軸において値が小さい方がより衝突の割合が少ないことを示す．
横軸は同じハッシュ値の数なので1は衝突していないことを意味し，2以上は衝突していることを表す．
したがって，ハッシュアルゴリズムAが最良であるとわかる．
4回程度の衝突ではハードウェアで処理可能だが，それ以上になるとソフトウェアで処理しなければならなくなるという仮定を行っている．
そのため，ハッシュアルゴリズムの評価の基準として4回衝突のところで縦の補助線を引いてある．
ハッシュアルゴリズムAでは，４回衝突のとき，CCDF$=1.3\times 10^{-2}$であった．
この確率が十分小さいかどうかは，今後実装するハードウェアの処理速度に依存する．
\begin{figure}
  \centering
  \includegraphics[scale=0.6]{graph/hash_ccdf/hash_A_C_ccdf-crop.pdf}
  \caption{Complementary cumulative distribution function of same hash value with each hash algorithm A -- C．}
  \label{graph:hash_ccdf_A-C}
\end{figure}

\section{eTLDごとのハッシュ衝突率}
Fig. \ref{fig:table}のポインタテーブルを用いることで，異なるeTLDは区別されるので1つのeTLDに対するハッシュ値の衝突だけが問題となる．
したがって各eTLDについてだけハッシュ値の衝突率を求めればよい．
Fig. \ref{graph:etld_hash_ccdf}に各eTLDごとのハッシュアルゴリズムAのときのハッシュ衝突率を示す．

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.6]{graph/etld_hash_ccdf/etld_hash_ccdf-crop.pdf}
  \caption{Complementary cumulative distribution function of same hash value for each eTLD when hash algorith A．}
  \label{graph:etld_hash_ccdf}
\end{figure}

Fig. \ref{graph:etld_hash_ccdf}よりeTLDが\url{me}のときだけ衝突しない確率が他と比べ極端に低くなっていることがわかる．
これは次のように考えられる．eTLDがmeでは，\url{formspring.me}というサイトがデータの大半を占めており，\url{icn:/me/formspring/nandaghizzo/q/908453668}のようなICN-URLの形式である．
このときハッシュアルゴリズムAを用いると毎回異なるパラメータとなるのは最後の3文字つまり3桁の数字である．
これは投稿などのIDだと考えられるので連番である可能性が高い．
このことから1000件に1回は衝突することになり，今回\url{me}の件数は7720件であったため，
最大でも7回の衝突のみとなり結果的に数件の衝突に集中した．
他のeTLDについてはALL eTLDと近い傾向を示した．

\section{eTLDにRootを加えた場合}
eTLDのみだと同じeTLDをもつURLの数が大きいので衝突が発生しやすくなると考えた．そこでこれを細分化するために次の3種の規則によりRootをeTLDに追加する．
\begin{enumerate}
  \item comのときのRootの出現回数が10のRootをeTLDに加える(Fig. \ref{graph:ratio_of_pointer_all}, \ref{graph:ratio_of_pointer_detail}の赤線)．
  \item comのときのRootの出現回数の多い順の上位256をeTLDに加える(Fig. \ref{graph:ratio_of_pointer_all}の青線)．
  \item 2.に加えnetの上位256も加える(Fig. \ref{graph:ratio_of_pointer_all}の緑線)．
\end{enumerate}

Fig. \ref{graph:ratio_of_pointer_all}から加えるRoot部の数が多いほどポインタの数が増加することがわかる．
上記1の規則について詳しく見るためにFig. \ref{graph:ratio_of_pointer_detail}とTable \ref{tab:ratio_of_pointer_detail}に出現確率の多い上位10件のポインタを示す．
グラフから\url{twitter.com}と\url{google.com}が上位に入っていることがわかる．
そして，\url{com}が占める割合が60\%から25\%に減ったことにより，衝突確率が下がることが期待できる．

\begin{table}[h]
  \centering
  \caption{Top 10 of eTLD+Root, URL count and probability in the sampled URLs (147,315)．}
  \label{tab:ratio_of_pointer_detail}
  \begin{tabular}{@{}crrr@{}}
  \toprule
  ID & \multicolumn{1}{c}{eTLD+Root} & \multicolumn{1}{c}{URL count} & \multicolumn{1}{c}{Probability{[}\%{]}} \\ \midrule
  0 & com & 36423 & 24.7246 \\
  1 & net & 8285 & 5.624 \\
  2 & me & 7720 & 5.2405 \\
  3 & org & 5201 & 3.5305 \\
  4 & twitter.com & 4357 & 2.9576 \\
  5 & de & 3301 & 2.2408 \\
  6 & google.com & 3092 & 2.0989 \\
  7 & blogspot.com & 2667 & 1.8104 \\
  8 & jp & 2644 & 1.7948 \\
  9 & co.uk & 2576 & 1.7486 \\ \bottomrule
  \end{tabular}
\end{table}

Fig \ref{graph:pointer_hash_ccdf}にeTDLにRootを加えたときと，加えてないときのハッシュ値の衝突率の比較を示す．
グラフから\url{com}, \url{net}の衝突率がeTLDにRootを加えることで低減されていることがわかる．
例えば\url{com}について，衝突しない確率が92\%からeTLDにRootを加えることで96\%に向上した．
また，4回以上衝突する確率1.3\%から0.3\%に減少した．すなわち4倍以上の向上がみられた．

\begin{figure}[p]
  \centering
  \includegraphics[scale=0.57]{graph/ratio_of_pointer/ratio_of_pointer_all-crop.pdf}
  \caption{Probability of appearance of eTLD or eTLD + Root．Black line shows only eTLD．
  Red line shows eTLD + Root when number of appearance of Root is more than 10 in eTLD of com．
  Blue and green lines show eTLD + Root when top 256 most frequently appearing Root in eTLD of com, com and net, respectively．}
  \label{graph:ratio_of_pointer_all}
\end{figure}
\begin{figure}[p]
  \centering
  \includegraphics[scale=0.57]{graph/ratio_of_pointer/ratio_of_pointer_detail-crop.pdf}
  \caption{Detail of Fig. \ref{graph:ratio_of_pointer_all} of red line and black line (top 10 of pointer)．}
  \label{graph:ratio_of_pointer_detail}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[scale=0.65]{graph/pointer_hash_ccdf/pointer-hash-ccdf-crop.pdf}
  \caption{Complementary cumulative distribution function of same hash value for each eTLD when hash algorith A．}
  \label{graph:pointer_hash_ccdf}
\end{figure}


% \section{キーに含めたものとeTLDのもので別のハッシュアルゴリズム}

\section{まとめ}
ハッシュアルゴリズムAのような3回のXORを行うだけの軽量な計算負荷で求まる4バイトのハッシュ値でも，
ポインタテーブルを併用することにより5回以上の衝突確率を0.3\%に抑えることができた．


\chapter{結論}
本論文のICNのルーティングのためのURLのクラシフィケーションついてシミュレーションを用いて解析検討した結果をまとめ，結論とする．

\begin{enumerate}
  \item 3通りのハッシュアルゴリズムを提案した．ICN-URLを"/"で分割し，3バイトの文字列を切り出し，
      そのうちの2--3の文字列どうしのXOR演算から3バイトから4バイトのハッシュ値を生成した．
      このハッシュ値とICN-URLの対応をハッシュテーブルとして作成し，衝突確率を求めた．
  \item 衝突数を軽減するためにポインタを併用したハッシュ作成アルゴリズムを提案した．
  URLのeTLDの分布を調べることにより，\url{com}が60\%占めていて偏りが大きいことがわかった．
  そのため衝突率が大きくなっていた．
  \item eTLDにRootを加えることで偏りが大きかった\url{com}の占める割合を24\%に下げることで５回以上衝突する確率を0.3\%に抑えることができた．
  \item 上記ポインタとハッシュの併用を新たな検索手法として共同研究先に提案を行った．
\end{enumerate}

\subsection*{今後の課題}
\begin{enumerate}
  \item ハッシュアルゴリズムが簡易的なものだったので，eTLDをRootに加えた際にハッシュ値への寄与はなかった．
        そこで，eTLDをRootに加えた際にハッシュ値が変化するようなハッシュアルゴリズムの改良をする．
  \item 本研究では4回程度の衝突ではハードウェアで処理可能だが，それ以上になるとソフトウェアで処理しなければならなくなるという仮定のもと研究を行った．
        しかし，どの程度の衝突数であればハードウェアで処理可能であるかといったことは来年以降の課題とする．
\end{enumerate}


\chapter*{謝辞}
本研究を進めるにあたり，ご指導いただいた指導教員の井上一成教授に感謝いたします．

御助言を頂いた共同研究先の国立研究開発法人情報通信研究機構の大岡睦氏に感謝の意を表します．

\bibliography{thesis}
\bibliographystyle{junsrt}


\appendix
\chapter{作成したプログラム}
作成したプログラムの一部を付録として記載する．

詳細は\url{https://gitlab.com/inue-lab/icn-hash}にて公開しているのでそちらを参照．

\section{重複を削除する}
文字列の長さごとに分割し，分割したそれぞれにおいて重複を削除する．
\inputGofile[label=util/unique.go]{code/util/unique.go}

\section{ランダムにサンプルを抽出}
メルセンヌ・ツイスタにより生成した疑似乱数に対応する行を抽出する．
\inputGofile[label=util/random.go]{code/util/random.go}

\section{ICN-URLに変換する}
\inputGofile[label=icn/convert.go]{code/icn/convert.go}
\inputGofile[label=icn/pointer.go]{code/icn/pointer.go}

\section{ハッシュの計算}
コード中のhash5--7がハッシュアルゴリズムA--Cに対応する．
\inputGofile[label=hash/algo.go]{code/hash/algo.go}
\inputGofile[label=hash/calc.go]{code/hash/calc.go}
\inputGofile[label=hash/split.go]{code/hash/split.go}

\section{ハッシュの衝突数を数え上げる}
ハッシュの衝突数を数え上げてCCDFを計算する．
\inputGofile[label=hash/count.go]{code/hash/count.go}

\section{ハッシュテーブルとポインタテーブルの作成}
\inputGofile[label=table/split.go]{code/table/split.go}
\inputGofile[label=table/table.go]{code/table/table.go}

\end{document}
