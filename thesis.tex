% ------------------------------------------------------
% preamble
% ------------------------------------------------------

\documentclass[autodetect-engine, dvipdfmx-if-dvi, a4paper, ja=standard, 10pt, textwidth-limit=45]{bxjsbook}

\usepackage{ifthen}
\usepackage{ifxetex,ifluatex,ifuptex}

\ifthenelse{\boolean{xetex}}{
  % XeLaTeXの時
}{\ifthenelse{\boolean{luatex}}{
  % LuaLaTeXの時
  \usepackage{luatexja}
}{\ifthenelse{\boolean{upTeX}}{
  % upLaTeXの時
}{%else (pLaTeXと仮定する)
  % pLaTeX の時
}}}

\renewcommand{\figurename}{Fig. }
\renewcommand{\tablename}{Table }
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\mathtoolsset{showonlyrefs=true}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{fancyvrb}
\usepackage{url}
\usepackage[super]{cite}
\renewcommand\citeform[1]{[#1]}

\begin{document}

% ------------------------------------------------------
% front cover
% ------------------------------------------------------

{\LARGE
\vspace{1.0cm}
\begin{center}
  令和元年度卒業研究論文
\end{center}}

{\huge
\vspace{1.0cm}
\begin{center}
  URLの情報指向型クラシフィケーション
\end{center}}

{\LARGE
\vspace{13cm}
\begin{center}
  2020年2月7日(金)
\end{center}
\vspace{0.2cm}
\begin{center}
  \begin{tabular}{ccc}
    指導教員 & 井上一成 & 教授
  \end{tabular}
\end{center}
\vspace{0.2cm}
\begin{center}
  明石工業高等専門学校 \\
  電気情報工学科
\end{center}
\begin{center}
  \begin{tabular}{crl}
  報告者 & E1533 & 西 総一朗
  \end{tabular}
\end{center}}

\thispagestyle{empty}

\clearpage

% ------------------------------------------------------
% table of contents
% ------------------------------------------------------

\pagenumbering{roman}
\tableofcontents

\clearpage

% ------------------------------------------------------
% body
% ------------------------------------------------------

\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{序論}
\section{TCP/IPの課題}
1983年から今日のインターネットと呼ばれているネットワークにおいて通信プロトコルTCP/IPがデファクトスタンダードとなった\cite{Brief_History_of_the_Internet}．
約20年前のインターネットのトラヒックや利用形態は現在とは大きく異なっている．
1992年の全世界のインターネットトラフィックは1日あたり約100 GBであったが,その10年後の2002年には1秒あたり100 GBに増え，2017年には1秒あたり45,000 GB以上に到達した．
また利用形態も2017年においてはトラヒックの75\%をビデオコンテンツが占めている．
Ciscoによると全世界のインターネットトラヒックは2022年には150,700 GB/秒となりその82\%をビデオコンテンツが占めると予測されている\cite{Cisco_Visual_Networking_Index}．

また，インターネットの使用目的も変遷している．
当初はインターネットを高性能コンピュタあるいは高性能プリンタを利用するように，様々なリソースを遠隔から共有することが主な目的であった．
現在は情報の共有，情報の取得といった情報のやり取りが中心となっている．
それに伴って，通信形態も変化している．
従来のTCP/IPはホスト中心のHost-to-Hostの通信形態であり，IPプロトコルは位置情報であるネットワークアドレスを用いてホストアドレスを指定するというロケーション・オリエンテッド\footnote{Location-oriented: 地理的指向な}な通信であった．
ところが，現在は情報をユーザに送るというインフォメーション・セントリック\footnote{Information-Centric: 情報指向な}な通信形態に変わりつつある．

このようにTCP/IPの通信形態と現在のインターネットに求められている通信形態との間の差が広がっている．
情報の効率的な取得のために
P2P\footnote{Peer to Peer: インターネットにおいて一般的に用いられるクライアント・サーバ型モデルでは，データを保持・提供するサーバとそれに対してデータを要求・アクセスするクライアントという2つの立場が固定されているのに対して，各ピアに対して対等 にデータの提供及び要求・アクセスを行う自立分散型のネットワークモデル}や
CDN\footnote{Content Delivery Network: 頻繁に使われるWebサイトがあると一つのノード（サーバ）だけでは耐えきれないのでいくつかのノードにデータを分散しておき，各ユーザは分散したノードに接続して情報を取得するという方法}などの新しいプロトコルが提案された．
しかし，これらはロケーション・セントリックなTCP/IPネットワーク上のプロトコルであるので本質的な解決ではない．
本来，情報を取得するという行為に対して，ネットワークアドレスやホストアドレスなどを意識する必要はなく，
もし近くにある通信機器が当該コンテンツ(情報)\footnote{参考文献\cite{Networking_Named_Content}では情報(Information)とコンテンツ(Contents)は同様の意味で用いられている．本稿でも同様の意味で用いる．}を持っておりそこから情報を取得できるなら，それはより効率的であり将来の通信量増大にも対応できると考えられる．
そこで，情報を効率的に取得するために情報指向ネットワーク:\ Information-Centric-Network (ICN)\cite{Networking_Named_Content}というプロトコル体系が提案された\cite{ICN_prototype}．

\section{情報指向ネットワーク}
情報指向ネットワーク(ICN)においてユーザはサーバのIPアドレスではなくコンテンツ名を指定してコンテンツ取得要求を行い，
そのコンテンツ要求を受け取った近隣のルータやノードが当該コンテンツを保持していた場合，それらはユーザに対してそのコンテンツを直接転送するプロトコル体系である．
ICNにおいて情報を保持している者をパブリッシャ(Publisher)，情報の取得要求を出すものをサブスクライバ(Subscriber)と呼ぶ．
またICNでは各コンテンツ(情報)に対してコンテンツ名(名前)が対応付けられている．

ICNへのアプローチとして様々なが研究がなされているが，現在最も多くの研究者により研究されているNamed Data Networking (NDN)\cite{NDN} 及びその前身であるContent Centric Networking (CCN)\cite{CCN} を代表的なICNアーキテクチャとして述べる．
CCNアーキテクチャはパロアルト研究所\footnote{Palo Alto Research Center (PARC) : アメリカ合衆国のカリフォルニア州パロアルトにある研究開発企業}により研究されているICNの先駆となった本格的なアーキテクチャである．
また，US Future Internet Architectureプログラム\footnote{NSF FUTURE INTERNET ARCHITECTURE PROJECT (http://www.nets-fia.net/)}によって資金提供されたNDNプロジェクトは，CCNアーキテクチャをさらに発展させたものである．

\paragraph{コンテンツ名}
NDNにおけるコンテンツ名の命名規則は階層構造になっており，現在のインターネットで流通している識別子であるUniform-Resource-Locator (URL)に似ている．
たとえば，コンテンツ名は\url{/aueb.gr/ai/main.html}となる．
ただし，コンテンツ名は必ずしもURLとは一致せず，最初のセクション\footnote{"/"で区切られた部分をセクションと呼ぶ}はDNS名またはIPアドレスなどの形式である必要もない．
つまりNDNでは，各セクションについての具体的な規格は定義されていない．
またコンテンツ取得要求において，要求されたコンテンツ名のプレフィックスの名前を持つ情報と一致すると見なされる．
たとえば，\url{/aueb.gr/ai/main.html/_v1/_s1}は\url{/aueb.gr/ai/main.html}という名前のコンテンツと一致する．
これは要求されたコンテンツの初版であり，コンテンツを分割したセグメントの最初のデータを表している．
このデータを受信したあとにSubscriberは\url{/aueb.gr/ai/main.html/_v1/_s2}により次のセグメントを要求することや，新たなバージョンを要求することもできる．
このようにコンテンツを分割して扱う際にはコンテンツ名にそのメタデータを付与することが可能である．

\paragraph{名前解決とデータルーティング}
NDNにおいて，Subscriberはコンテンツを取得する際はコンテンツ取得要求であるINTERESTパケットを発行して，PublisherからのDATAパケットの形式で到着するコンテンツを取得する．
INTEREST/DATAパケットは，それぞれ要求/転送されるコンテンツのコンテンツ名を持つ．
Fig. \ref{fig:ccn_ndn_routing}に示すように，すべてのパケットはContent Router (CR)によってホップバイホップ(hop by hop)で転送され，
各CRには3つのデータ構造(Forwarding Information Base (FIB), Pending Interest Table (PIT), Content Store (CS))がある．
FIBは，INTERESTパケットを適切なデータソースに転送するために使用するインターフェイスとコンテンツ名をマッピングする．
PITは，保留中のINTERESTパケットが到着した受信インターフェイス，つまり一致するDATAパケットが転送されてきたときに返送するインターフェースとコンテンツ名をマッピングすることでINTERESTパケットを追跡する．
最後に，CSはCRを通過したコンテンツのローカルキャッシュとして機能する.

INTERESTパケットが到着すると，CRはコンテンツ名を抽出し要求されたプレフィックスと一致する名前を持つCSのコンテンツを探す．
CSでキャッシュが見つかった場合，すぐにDATAパケットとして受信インターフェイスを介して送返され，INTERESTパケットは破棄される．
それ以外の場合，CRはこのINTERESTパケットを転送するインターフェースを決定するために，FIBで最長プレフィックス検索を実行する．
FIBでエントリが見つかった場合，CRはPITにINTERESTパケットの受信インターフェイスとコンテンツ名を記録し，FIBが示すCRにINTERESTパケットを転送します．
Fig. \ref{fig:ccn_ndn_routing}では，Subscriberは\url{/aueb.gr/ai/new.htm}という名前のINTERESTパケットを送信する(矢印1〜3)．
PITにコンテンツ名のエントリが既に含まれている場合，つまりこのコンテンツが既に要求されている場合，CRは受信インターフェイスをこのPITエントリに追加し，INTERESTパケットを破棄する．

要求されたコンテンツ名に一致するコンテンツがPublisherまたはCSで見つかった場合，INTERESTパケットは破棄され，コンテンツはDATAパケットとして返送される．
このDATAパケットは，PITで維持されている状態に基づいてホップバイホップ方式でSubscriberに転送される．
具体的には，CRはDATAパケットを受信すると，対応するコンテンツをCSに保存し，PITで最長プレフィックス検索を実行して，DATAパケットに一致するエントリを見つける．
PITエントリに複数のインターフェイスがある場合，DATAパケットが複製され，マルチキャスト配信が実現される．
最後に，CRはDATAパケットをこれらのインターフェイスに転送し，PITからエントリを削除する(矢印4〜6)．
PITに一致するエントリがない場合，CRはDATAパケットを重複データとして破棄する．
NDNでは，DATAパケットはINTERESTパケットによってPITに残された経路に従うため，名前解決とデータルーティングは対称である\cite{A_Survey_of_Information-Centric_Networking_Research}．

\paragraph{ICNの実用化に向けて}
ICNにおけるContents Router (CR)は未だに研究段階にありソフトウェアとして参照実装\footnote{Cefore: \url{https://cefore.net/} NICTにより開発されたCCNx準拠のTCP/IP上でCCNパケットをシミュレートするソフトウェアルータ}はあるが，ハードウェアとして実装されたものはない．
ICNの実用化を行うため，CRのハードウェアによる実装が不可欠である．
ハードウェア実装に向けた課題として，TCP/IPにおけるIPアドレスの代わりにコンテンツ名を用いて名前解決とルーティングを行うためCRでの処理が複雑であり，各テーブルに必要な記憶容量も増加するという点が挙げられる．
この問題を解決するためにコンテンツ名に対してハッシュ化\footnote{本稿ではあるデータを規則に則って処理したときに出力されるものをハッシュ，その規則をハッシュアルゴリズム，またこの処理を行うことをハッシュ化と呼ぶ．}を行うことによりルーティングに用いる識別子の圧縮などが研究されている\cite{saino2013hash}\cite{bloom_filter}．しかし，これらは既存のハッシュアルゴリズム\footnote{MD5,\ SHA1など}を用いているため，ハードウェアで実装するには複雑過ぎる．
また，ICNにおけるコンテンツ名のハッシュ化という用途では完全に衝突のないハッシュを用いるより，多少の衝突を許容しながらも高速に計算可能なハッシュアルゴリズムが求められる．
この多少の衝突を許容するために各テーブルにおける新たなデータ構造による検索手法も求められる．


\section{本研究の目的}
本研究では，上記課題を解決するために新たなデータ構造による検索手法と高速で軽量なハッシュアルゴリズムを提案，検証することである．
コンテンツ名はランダムな文字列ではなくある程度自然言語的な規則があるのでそれを用いることで軽量化を図る．

\begin{figure}[h]
  \centering
  \includegraphics[width=145mm]{fig/CCN_NDN_Routing-crop.pdf}
  \caption{The CCN/NDN architecture．CR stands for Content Router, FIB for Forwarding Information Base, PIT for Pending Interest Table, CS for Content Store (Excerpt from \cite{A_Survey_of_Information-Centric_Networking_Research})．}
  \label{fig:ccn_ndn_routing}
\end{figure}


\chapter{解析手法}

\section{URLの構造}
NDNのコンテンツ名はURLに似ているのでまずURLの階層構造について調べる．

Uniform-Resource-Locator(URL)はRFC1738\cite{rfc1738}により規格化されており，リソースの位置を特定するために用いられる．
HTTP URLの構造をFig. \ref{fig:http_url_structure}に示す．また，Table \ref{tab:http_url_variables_description}に各変数の説明を示す．

\begin{figure}[h]
  \centering
  \begin{BVerbatim}
    <scheme>://<host>:<port>/<path>?<searchpart>
  \end{BVerbatim}
  \label{fig:http_url_structure}
  \caption{HTTP URL Structure}
\end{figure}

\begin{table}[h]
  \centering
  \label{tab:http_url_variables_description}
  \caption{HTTP URL variables description\cite{rfc1738}}
  \begin{tabular}{@{}cp{12cm}@{}}
    \toprule
    Variables & \multicolumn{1}{c}{Description} \\ \midrule
    \verb|<scheme>| & \verb|http|, \verb|https|などのプロトコル体系を表す． \\
    \verb|<host>| & ネットワークホストのドメイン名，またはIPアドレス．ドメイン名は"."によって区切られるドメインラベルの連続． \\
    \verb|<port>| & 接続先のポート番号．デフォルトのポート番号(80,443)以外のポートを指定するときのみコロンで区切って続ける．\\
    \verb|<path>| & HTTPセレクタでリソースの位置を指定する． \\
    \verb|<searchpart>| & 検索パラメータである．これが省略されたときは"?"も省略される． \\ \bottomrule
  \end{tabular}
\end{table}

URLは\url{host}部によって階層構造に分けることができる．
\url{host}部はドメイン名かIPアドレスによって構成されているが，ドメイン名に注目する．
Domain Name System(DNS)は木構造でありドメイン名にはその階層構造が反映されている．
前述のドメイン名とは実際にはFully Qualified Domain Name(FQDN)\cite{rfc1983}のことであり，Fig. \ref{fig:fqdn_structure}のような構造である．
FQDNは"."で区切られた各ラベルの連続であり右端の"."がルートとなる．
ルートから順に各ラベルはTop-Level Domain(TLD), Second-Level Domain(SLD), 3rd-Level Domain(3rdLD), 4th-Level Domain(4thLD) ... のように名前がつけられている．
また左端のラベルをHost Nameと呼び，それ以外のラベルをまとめてDomain Nameと呼ぶ．

Top-Level Domain (TLD)にはcountry code TLD(ccTLD), generic TLD (gTLD), restricted generic TLD(grTLD), sponsored TLD (sTLD)などがありそれぞれICANNにより管理されている\cite{tld}．
それぞれの例をTable \ref{tab:example_tld}に示す．
\begin{figure}[h]
  \centering
  \includegraphics[width=60mm]{fig/fqdn_structure-crop.pdf}
  \caption{Fully Qualified Domain Name(FQDN) structure. FQDN include last ".". TLD stands for Top-Level Domain, SLD for Second-Level Domain, 3rdLD for 3rd-Level Domain, 4thLD for 4t-Level Domain.}
  \label{fig:fqdn_structure}
\end{figure}

\begin{table}[h]
  \centering
  \caption{Example of each TLDs}
  \label{tab:example_tld}
  \begin{tabular}{@{}cccc@{}}
  \toprule
  ccTLD & gTLD & grTLD & sTLD \\ \midrule
  .jp & .com & .biz & .aero \\
  .uk & .info & .name & .asia \\
  .cn & .net & .pro & .cat \\ \bottomrule
  \end{tabular}
\end{table}

また，各ブラウザによるクッキーの適応可能範囲決定のために"１つのサイト"の単位というものが求められた．それを受けてPublic Suffixというものが提案された\footnote{例えば，\url{example.co.jp}や\url{a.example.co.jp}のPublic Suffixは\url{co.jp}で，\url{example.co.jp}が
サイトの単位となる．もし，\url{example.co.jp}がドメインが\url{co.jp}や\url{jp}のクッキーを発行できてしまうと，異なるサイトであるはずの\url{test.co.jp}にも干渉できてしまう．これを防ぐためにクッキーの処理ではPSLを参照するようになっている．}．
これはeffective TLD (eTLD)とも呼ばれ，TLDや\url{co.jp}などの実質的にTLDのように機能するドメインを指す．
TLD内のサブドメインの構造はTLDごとに異なるため，機械的にeTLDを決定することはできない．
それを解決するためにPublic Suffix List (PSL)\cite{psl}として一覧表が管理されている．

\section{性能の評価手順}
Fig. \ref{fig:ccn_ndn_routing}のテーブルをFig. \ref{fig:ndn_table}に再掲する．
FIB, PIT, CSの３つのテーブルはNameをキーとしており，その分布を評価することでアルゴリズムの性能を評価する．
評価のためにFig. \ref{fig:table}に示す手順を行った．
入手可能な全URLのリスト(All list)から10MB程度のサイズになるようにランダムに抽出したリスト(Sampled list)を作る．
そのリストからポインタとハッシュのテーブルを作る．
\begin{figure}[h]
  \centering
  \includegraphics[width=50mm]{fig/ndn_table-crop.pdf}
  \caption{Tables of FIB, PIT, CS.}
  \label{fig:ndn_table}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=120mm]{fig/table-crop.pdf}
  \caption{}
  \label{fig:table}
\end{figure}


\section{解析データ}
シミュレーションに用いるデータとして，The Content Name Collection\footnote{\url{http://www.icn-names.net/} にて"The Content Name Collection"というバーゼル大学による情報指向ネットワークのためのデータセットが2019年10月まで公開されていたが，ドメインの有効期限切れのため現在は全く関係のない中国の会社によりドメインが取得されている．}
で公開されている情報指向ネットワークのための膨大なURLのデータセットを用いる．
そのデータセットの内の一つである\url{urls.txt}を使う．
\url{urls.txt}はFig. \ref{fig:urls_txt_10}のように改行で区別されているURLのリストになっている．
\url{urls.txt}の概要をTable \ref{tab:dataset_overview}に示す．

\begin{figure}[h]
  \centering
  \begin{BVerbatim}
http://www.google.com
http://images.google.com/imgres
http://www.19lou.com
http://www.sfd.com
http://www.baidu.com
http://www.sina.com.cn
http://www.netvibes.com/
http://www.google.com/search
http://images.google.com/
http://wrestlingabrasil.blogspot.com/
...
...
...
  \end{BVerbatim}
  \caption{Sample 10 in the urls.txt}
  \label{fig:urls_txt_10}
\end{figure}
\begin{table}[h]
  \centering
  \caption{Dataset "urls.txt" overview}
  \label{tab:dataset_overview}
  \begin{tabular}{@{}cccc@{}}
    \toprule
    Dataset        & Number of URLs                      & unique                 & File size                                            \\ \midrule
    \url{urls.txt} & \multicolumn{1}{r}{$2,144,314,011$} & \multicolumn{1}{r}{no} & \multicolumn{1}{r}{121 GB ($130,782,049,461$ Bytes)} \\ \bottomrule
  \end{tabular}
\end{table}


\section{プログラム}
ハッシュアルゴリズムの検証・URLの構造解析を行うためにシミュレーションプログラムをGolangで作成した．

\url{urls.txt}の前処理として以下の工程を行う．
\begin{enumerate}
  \item このデータには重複が含まれているので重複を削除する．
  \item 各CRでの実際的なURLは10MBほどであるという仮定のうえ，ランダムな10MBごとのサンプルを抽出する．
\end{enumerate}




\section{コンテンツ名への変換}

\section{ハッシュアルゴリズム}

\chapter{衝突数の検証結果}
\subsection{ハッシュアルゴリズム}
\section{URLの分類手法を利用するとき}
\section{ハッシュとURLの分類手法を併用したとき}

\bibliography{thesis}
\bibliographystyle{junsrt}

\end{document}
